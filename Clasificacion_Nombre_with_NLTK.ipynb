{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clasificacion_Nombre with NLTK",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXFMNFzmroTa"
      },
      "source": [
        "# **Importamos Pandas, Numpy, NLTK y Random**\n",
        "\n",
        "**Tambien hacer un git clone del repositorio en github.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_w5NMvBrgpQ",
        "outputId": "33c8df5a-da40-465d-852f-9ff9804835e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk, random\n",
        "!git clone https://github.com/jvalhondo/spanish-names-surnames"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'spanish-names-surnames' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uXymvbsuTF_"
      },
      "source": [
        "# **Cargamos la Data.**\n",
        "\n",
        "Si vemos en google colab se cargaron diferentes archivos .csv que contienen los nombres masculinos y femeninos por separado.\n",
        "\n",
        "Lo que hice, fue crear una funcion que dada el path del archivo, leyera, sacara los nombres y segun el genero que le indicaramos creara un array con el (nombre, genero).\n",
        "\n",
        "Se unio los datos de nombres masculinos y femeninos y se hizo un shuffle para que no quedaran ordenados por genero.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbqDwFd-r2Un",
        "outputId": "57e3fdef-2993-479c-a25a-54e6cfa2c8df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "def fromCSVtoArray(dataPath, genre):\n",
        "  x_names = pd.read_csv(dataPath)\n",
        "  x_names = x_names.dropna(axis = 0)\n",
        "  x_names = x_names['name']\n",
        "  x_names = np.asarray(x_names)\n",
        "\n",
        "  return [(name, genre) for name in x_names] \n",
        "\n",
        "female = fromCSVtoArray('/content/spanish-names-surnames/female_names.csv', 'female')\n",
        "male = fromCSVtoArray('/content/spanish-names-surnames/male_names.csv', 'male')\n",
        "data = female + male\n",
        "\n",
        "random.shuffle(data)\n",
        "data[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('FREDRICK', 'male'),\n",
              " ('HONG', 'female'),\n",
              " ('JOSE ELIAS', 'male'),\n",
              " ('CESAR AGUSTO', 'male'),\n",
              " ('SHUMEI', 'female'),\n",
              " ('MIRCEA ADRIAN', 'male'),\n",
              " ('LIZ PATRICIA', 'female'),\n",
              " ('MARIO ALFONSO', 'male'),\n",
              " ('PAUL GEORGE', 'male'),\n",
              " ('ROSA SOLEDAD', 'female')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW6PU-WNu7XA"
      },
      "source": [
        "Podemos guardar el array de nuestros datos, de tal forma siempre trabajaremos con el mismo dataset de entrenamiento y de test cuando se separe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D7YSs24uAHd"
      },
      "source": [
        "#np.save('nombres.npy', data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KmMSNQ6uDXF"
      },
      "source": [
        "data = np.load('nombres.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhodEHbgvTNV"
      },
      "source": [
        "# **Indicaremos las funciones que utilizamos para obtener los atributos**\n",
        "\n",
        "\n",
        "* ultimaLetra: Solo utiliza la ultima letra.\n",
        "* atributos: Primera y ultima letra.\n",
        "* atributos1: Primer y ultima letra, conteo de cuantas letras, y si contiene o no una letra.\n",
        "* atributos2: Separa los nombres con split(' '), para trabajar con el segundo nombre en caso de que lo tenga. Aplica las mismas funciones que atributos1 pero almacena tanto del segundo como el primer nombre. \n",
        "* atributos3: Utiliza la misma logica que atributos2, solo que en vez de analizar todas las letras del abecedario, recorre solamente las vocales.\n",
        "\n",
        "**Actulizacion 1.**\n",
        "\n",
        "* atributos4: Utiliza la misma logica que atributos3, pero agrega atributos que describen si la primera y si la ultima letra es vocal en el primer y segundo nombre.  \n",
        "* atributos5: Utiliza lo mismo que atributos4, solo que indica si tiene un segundo nombre. \n",
        "* atributos6: Utiliza lo mismo que atributos4, solo que indica la longitud de los nombres\n",
        "\n",
        "**Actualizacion 3.**\n",
        "\n",
        "* atributos7: Utiliza la misma informacion que atributos4, pero agrega informacion referente a las 4 ultimas letras del primer nombre y del segundo nombre. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2aBUkbwr_fB"
      },
      "source": [
        "def ultimaLetra(nombre):\n",
        "    atrib = {}\n",
        "    atrib[\"ultima_letra\"] = nombre[-1].lower()\n",
        "    \n",
        "    return atrib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGvzEF3lsBKt"
      },
      "source": [
        "def atributos(nombre):\n",
        "    atrib = {}\n",
        "    atrib[\"primera_letra\"] = nombre[0].lower()\n",
        "    atrib[\"ultima_letra\"] = nombre[-1].lower()\n",
        "    \n",
        "    return atrib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4AQsoX5sDZQ"
      },
      "source": [
        "def atributos1(nombre):\n",
        "    atrib = {}\n",
        "    atrib[\"primera_letra\"] = nombre[0].lower()\n",
        "    atrib[\"ultima_letra\"] = nombre[-1].lower()\n",
        "    for letra in 'abcdefghijklmnopqrstuvwxyz':\n",
        "        atrib[\"count({})\".format(letra)] = nombre.lower().count(letra)\n",
        "        atrib[\"has({})\".format(letra)] = (letra in nombre.lower())\n",
        "    return atrib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooUrg5zmsFeu"
      },
      "source": [
        "def atributos2(nombre):\n",
        "    primerSegundoNombre = nombre.split(' ')\n",
        "\n",
        "    atrib = {}\n",
        "    for i in range(len(primerSegundoNombre)):\n",
        "      atrib[\"primera_letra_{}\".format(i + 1)] = primerSegundoNombre[i][0].lower()\n",
        "      atrib[\"ultima_letra_{}\".format(i + 1)] = primerSegundoNombre[i][-1].lower()\n",
        "      for letra in 'abcdefghijklmnopqrstuvwxyz':\n",
        "          atrib[\"count({})_{}\".format(letra, i + 1)] = primerSegundoNombre[i].lower().count(letra)\n",
        "          atrib[\"has({})_{}\".format(letra, i + 1)] = (letra in primerSegundoNombre[i].lower())\n",
        "    return atrib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_oDlBtAxegj"
      },
      "source": [
        "def atributos3(nombre):\n",
        "    primerSegundoNombre = nombre.split(' ')\n",
        "\n",
        "    atrib = {}\n",
        "    for i in range(len(primerSegundoNombre)):\n",
        "      atrib[\"primera_letra_{}\".format(i + 1)] = primerSegundoNombre[i][0].lower()\n",
        "      atrib[\"ultima_letra_{}\".format(i + 1)] = primerSegundoNombre[i][-1].lower()\n",
        "      for letra in 'aeiou':\n",
        "          atrib[\"count({})_{}\".format(letra, i + 1)] = primerSegundoNombre[i].lower().count(letra)\n",
        "          atrib[\"has({})_{}\".format(letra, i + 1)] = (letra in primerSegundoNombre[i].lower())\n",
        "    return atrib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZWsPNzA2pTA"
      },
      "source": [
        "def atributos4(nombre):\n",
        "    primerSegundoNombre = nombre.split(' ')\n",
        "\n",
        "    atrib = {}\n",
        "    for i in range(len(primerSegundoNombre)):\n",
        "      atrib[\"primera_letra_{}\".format(i + 1)] = primerSegundoNombre[i][0].lower()\n",
        "      atrib[\"primera_letra_vocal_{}\".format(i + 1)] = primerSegundoNombre[i][0].lower() in 'aieou'\n",
        "      atrib[\"ultima_letra_vocal_{}\".format(i + 1)] = primerSegundoNombre[i][-1].lower() in 'aieou'\n",
        "      atrib[\"ultima_letra_{}\".format(i + 1)] = primerSegundoNombre[i][-1].lower()\n",
        "      for letra in 'aeiou':\n",
        "          atrib[\"count({})_{}\".format(letra, i + 1)] = primerSegundoNombre[i].lower().count(letra)\n",
        "          atrib[\"has({})_{}\".format(letra, i + 1)] = (letra in primerSegundoNombre[i].lower())\n",
        "    return atrib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2RzwuHx2_k3"
      },
      "source": [
        "def atributos5(nombre):\n",
        "    primerSegundoNombre = nombre.split(' ')\n",
        "\n",
        "    atrib = {}\n",
        "    atrib[\"segundo_nombre\"] = len(primerSegundoNombre) > 1\n",
        "    for i in range(len(primerSegundoNombre)):\n",
        "      atrib[\"primera_letra_{}\".format(i + 1)] = primerSegundoNombre[i][0].lower()\n",
        "      atrib[\"primera_letra_vocal_{}\".format(i + 1)] = primerSegundoNombre[i][0].lower() in 'aieou'\n",
        "      atrib[\"ultima_letra_vocal_{}\".format(i + 1)] = primerSegundoNombre[i][-1].lower() in 'aieou'\n",
        "      atrib[\"ultima_letra_{}\".format(i + 1)] = primerSegundoNombre[i][-1].lower()\n",
        "      for letra in 'aeiou':\n",
        "          atrib[\"count({})_{}\".format(letra, i + 1)] = primerSegundoNombre[i].lower().count(letra)\n",
        "          atrib[\"has({})_{}\".format(letra, i + 1)] = (letra in primerSegundoNombre[i].lower())\n",
        "    return atrib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr3AJ0m46nyM"
      },
      "source": [
        "def atributos6(nombre):\n",
        "    primerSegundoNombre = nombre.split(' ')\n",
        "\n",
        "    atrib = {}\n",
        "    \n",
        "    for i in range(len(primerSegundoNombre)):\n",
        "      atrib[\"longitud_{}.format(i + 1)\"] = len(primerSegundoNombre[i])\n",
        "      atrib[\"primera_letra_{}\".format(i + 1)] = primerSegundoNombre[i][0].lower()\n",
        "      atrib[\"primera_letra_vocal_{}\".format(i + 1)] = primerSegundoNombre[i][0].lower() in 'aieou'\n",
        "      atrib[\"ultima_letra_vocal_{}\".format(i + 1)] = primerSegundoNombre[i][-1].lower() in 'aieou'\n",
        "      atrib[\"ultima_letra_{}\".format(i + 1)] = primerSegundoNombre[i][-1].lower()\n",
        "      for letra in 'aeiou':\n",
        "          atrib[\"count({})_{}\".format(letra, i + 1)] = primerSegundoNombre[i].lower().count(letra)\n",
        "          atrib[\"has({})_{}\".format(letra, i + 1)] = (letra in primerSegundoNombre[i].lower())\n",
        "    return atrib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGARbeawPrpu"
      },
      "source": [
        "def atributos7(nombre):\n",
        "    primerSegundoNombre = nombre.split(' ')\n",
        "\n",
        "    atrib = {}\n",
        "\n",
        "    #atrib[\"ultimas_4_letras_1\"] = primerSegundoNombre[0][-1:-5:-1].lower()\n",
        "    #atrib[\"ultimas_4_letras_2\"] = primerSegundoNombre[1][-1:-5:-1].lower()\n",
        "\n",
        "\n",
        "    for i in range(len(primerSegundoNombre)):\n",
        "      atrib[\"ultimas_4_letras_{}\".format(i + 1)] = primerSegundoNombre[i][-1:-5:-1].lower()\n",
        "      atrib[\"primera_letra_{}\".format(i + 1)] = primerSegundoNombre[i][0].lower()\n",
        "      atrib[\"primera_letra_vocal_{}\".format(i + 1)] = primerSegundoNombre[i][0].lower() in 'aieou'\n",
        "      atrib[\"ultima_letra_vocal_{}\".format(i + 1)] = primerSegundoNombre[i][-1].lower() in 'aieou'\n",
        "      atrib[\"ultima_letra_{}\".format(i + 1)] = primerSegundoNombre[i][-1].lower()\n",
        "      for letra in 'aeiou':\n",
        "          atrib[\"count({})_{}\".format(letra, i + 1)] = primerSegundoNombre[i].lower().count(letra)\n",
        "          atrib[\"has({})_{}\".format(letra, i + 1)] = (letra in primerSegundoNombre[i].lower())\n",
        "    return atrib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7Z8lyYxjZYk"
      },
      "source": [
        "# **Data Augmentation.** (Actualizacion 2)\n",
        "Podemos aumentar nuestros datos, de tal forma el modelo podra tener muchos mas datos de entrenamiento. \n",
        "\n",
        "* **dataAugmentation()**: Para probar esta tecnica cree esta funcion al principio que, lo que haria es recorrer nuestro dataset, y de tal forma que si el nombre completo esta conformado por dos nombres, podriamos tener dos datos mas. Por ejemplo: \"Ana Patricia\", podriamos tener: \"Ana\", \"Patricia\" y \"Ana Patricia\", en vez de solamente \"Ana Patricia\", los tres datos tienen la misma etiqueta \"female\", por lo que no afectaria. \n",
        "\n",
        "* **dataAugmentation2()**: Con esta segunda funcion, realice las mismas tecnicas de la anterior, solo que probe. Alternar el primer y segundo nombre, de tal forma que si tenemos \"Ana Patricia\", tendriamos ademas de las anteriores generadas por la primera funcion tambien tendriamos, \"Patricia Ana\" con la misma etiqueta. \n",
        "\n",
        "**Problemas:**\n",
        "\n",
        "El nombre \"Jose Maria\" y \"Maria Jose\", por ejemplo, no tienen la misma etiqueta cuando se intercambian entre si.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhxhSb3TP1vl"
      },
      "source": [
        "def dataAugmentation(data):\n",
        "  newData = data\n",
        "  for (n, g) in newData:\n",
        "    primerYSegundoNombre = n.split(\" \")\n",
        "    segundoNombre = len(primerYSegundoNombre) > 1\n",
        "\n",
        "    if segundoNombre:\n",
        "      newData = np.append(newData, [(primerYSegundoNombre[0], g)], axis = 0)\n",
        "      newData = np.append(newData, [(primerYSegundoNombre[1], g)], axis = 0)\n",
        "      \n",
        "    #print(newData[-1])\n",
        "  return newData"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fz8eqyVbV7L"
      },
      "source": [
        "def dataAugmentation2(data):\n",
        "  newData = data\n",
        "  \n",
        "  for (n, g) in newData:\n",
        "    primerYSegundoNombre = n.split(\" \")\n",
        "    segundoNombre = len(primerYSegundoNombre) > 1\n",
        "\n",
        "    if segundoNombre:\n",
        "      if not primerYSegundoNombre[0] in data[0]:\n",
        "        newData = np.append(newData, [(primerYSegundoNombre[0], g)], axis = 0)\n",
        "      \n",
        "      if not primerYSegundoNombre[1] in data[0]:\n",
        "        newData = np.append(newData, [(primerYSegundoNombre[1], g)], axis = 0)\n",
        "      \n",
        "      if not primerYSegundoNombre[1] + primerYSegundoNombre[0]  in data[0]:\n",
        "        newData = np.append(newData, [(primerYSegundoNombre[1] + primerYSegundoNombre[0], g)], axis = 0)\n",
        "\n",
        "  return newData"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui0y1zNxbv-S"
      },
      "source": [
        "dataAugmented2 = dataAugmentation2(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecuQ_BQoLXf8"
      },
      "source": [
        "np.save('dataAugmented.npy', dataAugmented2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qTWyZNqLcfO"
      },
      "source": [
        "dataAugmented2 = np.load('dataAugmented.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aB3APdJW0Jk",
        "outputId": "3592b3d8-0c7e-4c27-dc88-cea1840ffe0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape, dataAugmented2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((49339, 2), (145387, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPciRClfwOvQ"
      },
      "source": [
        "# **Fase de entrenamiento del Clasificador NaiveBayes**\n",
        "\n",
        "Utilizamos la funcion para preparar la data y luego entrenar el clasificar con la data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEv9wLFdsPpc"
      },
      "source": [
        "#fset = [(atributos4(n), g) for (n, g) in data]\n",
        "fset = [(atributos7(n), g) for (n, g) in dataAugmented2]\n",
        "\n",
        "train, test = fset[500:], fset[:500]\n",
        "fset\n",
        "classifierEspaniol = nltk.NaiveBayesClassifier.train(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdqNYdqXwnpd"
      },
      "source": [
        "# **Accuracy de nuestro modelo.**\n",
        "\n",
        "Utilizando el mismo dataset, podemos ver que los resultados de accuracy que nos dio con distintos atributos:\n",
        "\n",
        "* ultimaLetra: 0.792\n",
        "* atributos: 0.8\n",
        "* atributos1: 0.836\n",
        "* atributos2: 0.858\n",
        "* atributos3: 0.858\n",
        "\n",
        "Podriamos decir que la mejor funcion de atributos fue la de **atributos3**, ya que no solo recorrio las vocales y no todas las letras del abecedario y tuvo el mismo performance. \n",
        "\n",
        "**Nota:** Se podria intentar ver que otra informacion obtener del nombre, y ver si es mejor recorrer todo el abecedario o solo las vocales. \n",
        "\n",
        "**Actualizacion 1.**\n",
        "\n",
        "* atributos4: 0.87\n",
        "* atributos5: 0.866 *\n",
        "* atributos6: 0.866 **\n",
        "\n",
        "\\* Esto quiere decir que indicando si tiene un segundo nombre baja nuestro accuracy, por lo que deberia ser un dato que no se use. \n",
        "\n",
        "\\** Lo longitud de los nombres no influye tampoco.\n",
        "\n",
        "**Actualizacion 2: Data Augmentation.**\n",
        "\n",
        "* dataAugmentation(): 0.884 \n",
        "* dataAugmentation2(): 0.894\n",
        "\n",
        "**Actualizacion 3.**\n",
        "\n",
        "* **atributos7: 0.95** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b78oPU3xsRlb",
        "outputId": "df789cfd-2a35-4811-be54-b43956a267c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(nltk.classify.accuracy(classifierEspaniol, test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4a4hmvbRxvb"
      },
      "source": [
        "i = 0\n",
        "for (n, g) in data[:500]:\n",
        "  p = classifierEspaniol.classify(atributos7(n))\n",
        "  if p != g:\n",
        "    i += 1\n",
        "    print(n, g, p)\n",
        "\n",
        "print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goWgJDYRPQZj",
        "outputId": "9e73e3f4-4bcd-4d58-c9b6-6424bca23ae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(nltk.classify.accuracy(classifierEspaniol, train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9514173114220047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8uNaqh6NTTa",
        "outputId": "af200999-1225-447f-a9a7-0676ee4f37fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "classifierEspaniol.classify(atributos4('Luis Enrique'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'male'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    }
  ]
}